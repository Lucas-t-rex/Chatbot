import google.generativeai as genai
import requests
from flask import Flask, request, jsonify

# --- CONFIGURAÃ‡Ã•ES ---
# Chaves fornecidas por vocÃª
RESPONSIBLE_NUMBER = "554898389781"
GEMINI_API_KEY = "AIzaSyAhaTl7JDg_vzEteDSAIJwvGAhYAE95F24"

# Configure aqui os dados da sua Evolution API (InstÃ¢ncia 'chatbot')
EVOLUTION_API_URL = "https://evolution-api-lucas.fly.dev" # <--- SUBSTITUA PELO SEU URL
EVOLUTION_API_KEY = "1234"         # <--- SUBSTITUA PELA KEY GLOBAL

# ConfiguraÃ§Ã£o da IA
genai.configure(api_key=GEMINI_API_KEY)

# DefiniÃ§Ã£o da ÃšNICA ferramenta (IntervenÃ§Ã£o)
tools = [
    {
        "function_declarations": [
            {
                "name": "fn_solicitar_intervencao",
                "description": "Use esta funÃ§Ã£o quando o cliente pedir para falar com o dono, humano ou suporte.",
                "parameters": {
                    "type_": "OBJECT",
                    "properties": {
                        "motivo": {"type_": "STRING", "description": "O motivo do chamado."}
                    },
                    "required": ["motivo"]
                }
            }
        ]
    }
]

# Prompt do Sistema Simplificado
SYSTEM_PROMPT = """
VocÃª Ã© um assistente virtual de uma empresa.
Sempre que alguem falar de cabelo voce deve dizer "eu sou carequinha kkkk"
Seja educado, breve e profissional.
Seu objetivo Ã© conversar com o cliente.
SE E SOMENTE SE o cliente pedir para falar com o dono, humano ou suporte, CHAME a funÃ§Ã£o `fn_solicitar_intervencao`.
NÃ£o invente nÃºmeros de telefone.
"""

# Inicializa o Modelo
model = genai.GenerativeModel('gemini-2.5-flash-lite', tools=tools, system_instruction=SYSTEM_PROMPT)

# MemÃ³ria VOLÃTIL (apaga se reiniciar o cÃ³digo, pois nÃ£o estamos usando Banco de Dados)
# Formato: { 'numero_whatsapp': [historico_chat] }
memory = {} 

app = Flask(__name__)

def send_whatsapp_message(number, text):
    """Envia mensagem de texto via Evolution API"""
    url = f"{EVOLUTION_API_URL}/message/sendText/chatbot"
    
    payload = {
        "number": number,
        "textMessage": {"text": text},
        "options": {"delay": 1200, "presence": "composing"}
    }
    headers = {
        "apikey": EVOLUTION_API_KEY,
        "Content-Type": "application/json"
    }
    
    try:
        requests.post(url, json=payload, headers=headers)
        print(f"ðŸ“¤ Enviado para {number}: {text}")
    except Exception as e:
        print(f"âŒ Erro ao enviar WhatsApp: {e}")

@app.route('/webhook', methods=['POST'])
def webhook():
    data = request.json
    
    # Filtros bÃ¡sicos para nÃ£o processar lixo
    if data.get('event') != 'messages.upsert':
        return jsonify({"status": "ignored"}), 200
        
    msg_data = data.get('data', {})
    key = msg_data.get('key', {})
    
    # Ignora mensagens do prÃ³prio bot ou de grupos
    if key.get('fromMe') or 'g.us' in key.get('remoteJid', ''):
        return jsonify({"status": "ignored"}), 200

    remote_jid = key.get('remoteJid')
    clean_number = remote_jid.split('@')[0]
    
    # Pega o texto da mensagem
    user_msg = msg_data.get('message', {}).get('conversation') or \
               msg_data.get('message', {}).get('extendedTextMessage', {}).get('text')

    if not user_msg:
        return jsonify({"status": "no_text"}), 200

    print(f"ðŸ“© Recebido de {clean_number}: {user_msg}")

    # --- LÃ“GICA DO GEMINI ---
    try:
        # Inicia ou recupera histÃ³rico da memÃ³ria RAM
        if clean_number not in memory:
            memory[clean_number] = []
        
        chat = model.start_chat(history=memory[clean_number])
        response = chat.send_message(user_msg)
        
        # Verifica se a IA chamou a ferramenta (IntervenÃ§Ã£o)
        tool_call = None
        if response.candidates and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if part.function_call:
                    tool_call = part.function_call
                    break
        
        if tool_call and tool_call.name == "fn_solicitar_intervencao":
            # 1. Avisa o Dono
            motivo = tool_call.args.get("motivo", "NÃ£o especificado")
            msg_dono = f"ðŸš¨ INTERVENÃ‡ÃƒO SOLICITADA!\nCliente: {clean_number}\nMotivo: {motivo}"
            send_whatsapp_message(RESPONSIBLE_NUMBER, msg_dono)
            
            # 2. Responde ao cliente
            reply_text = "Entendi. JÃ¡ chamei o responsÃ¡vel e ele vai entrar em contato com vocÃª em breve!"
            send_whatsapp_message(clean_number, reply_text)
            
            # Atualiza memÃ³ria com a resposta
            memory[clean_number].append({'role': 'user', 'parts': [user_msg]})
            memory[clean_number].append({'role': 'model', 'parts': [reply_text]})

        else:
            # Resposta normal (texto)
            reply_text = response.text
            send_whatsapp_message(clean_number, reply_text)
            
            # Atualiza memÃ³ria
            memory[clean_number].append({'role': 'user', 'parts': [user_msg]})
            memory[clean_number].append({'role': 'model', 'parts': [reply_text]})

    except Exception as e:
        print(f"âŒ Erro na IA: {e}")

    return jsonify({"status": "ok"}), 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000)