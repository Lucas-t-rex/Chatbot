import google.generativeai as genai
import requests
import os
from flask import Flask, request, jsonify
from datetime import datetime
from dotenv import load_dotenv
import base64
import threading
from pymongo import MongoClient
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail
from apscheduler.schedulers.background import BackgroundScheduler
import json 

# --- 1. IDENTIDADE DO CLIENTE ATUALIZADA ---
CLIENT_NAME = "Marmitaria Sabor do Dia" 
# (RESPONSIBLE_NUMBER removido, pois este bot n√£o tem interven√ß√£o)

load_dotenv()
EVOLUTION_API_URL = os.environ.get("EVOLUTION_API_URL")
EVOLUTION_API_KEY = os.environ.get("EVOLUTION_API_KEY", "1234") 
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MONGO_DB_URI = os.environ.get("MONGO_DB_URI")

COZINHA_WPP_NUMBER = "554898389781"
MOTOBOY_WPP_NUMBER = "554499242532"

BIFURCACAO_ENABLED = bool(COZINHA_WPP_NUMBER and MOTOBOY_WPP_NUMBER)
if BIFURCACAO_ENABLED:
    print(f"‚úÖ Plano de Bifurca√ß√£o ATIVO. Cozinha: {COZINHA_WPP_NUMBER}, Motoboy: {MOTOBOY_WPP_NUMBER}")
else:
    print("‚ö†Ô∏è Plano de Bifurca√ß√£o INATIVO. (Configure COZINHA_WPP_NUMBER e MOTOBOY_WPP_NUMBER no .env)")
# --- FIM DA NOVA SE√á√ÉO ---

try:
    client = MongoClient(MONGO_DB_URI)
    
    db_name = CLIENT_NAME.lower().replace(" ", "_").replace("-", "_")
    
    db = client[db_name] 
    conversation_collection = db.conversations
    
    print(f"‚úÖ Conectado ao MongoDB para o cliente: '{CLIENT_NAME}' no banco de dados '{db_name}'")
except Exception as e:
    print(f"‚ùå ERRO: N√£o foi poss√≠vel conectar ao MongoDB. Erro: {e}")

if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
    except Exception as e:
        print(f"AVISO: A chave de API do Google n√£o foi configurada corretamente. Erro: {e}")
else:
    print("AVISO: A vari√°vel de ambiente GEMINI_API_KEY n√£o foi definida.")

conversations_cache = {}
message_buffer = {}
message_timers = {}

modelo_ia = None
try:
    modelo_ia = genai.GenerativeModel('gemini-2.5-flash') # Recomendo usar o 1.5-flash
    print("‚úÖ Modelo do Gemini inicializado com sucesso.")
except Exception as e:
    print(f"‚ùå ERRO: N√£o foi poss√≠vel inicializar o modelo do Gemini. Verifique sua API Key. Erro: {e}")

def save_conversation_to_db(contact_id, sender_name, customer_name, chat_session, tokens_used):
    """Salva o hist√≥rico, nomes e atualiza a contagem de tokens no MongoDB."""
    try:
        history_list = [
            {'role': msg.role, 'parts': [part.text for part in msg.parts]}
            for msg in chat_session.history
        ]
        
        update_payload = {
            'sender_name': sender_name, # Nome do contato no WhatsApp (Ex: Gauch√£o)
            'history': history_list,
            'last_interaction': datetime.now()
        }
        # Adiciona o nome real do cliente ao payload se ele for conhecido
        if customer_name:
            update_payload['customer_name'] = customer_name

        conversation_collection.update_one(
            {'_id': contact_id},
            {
                '$set': update_payload,
                '$inc': {
                    'total_tokens_consumed': tokens_used
                }
            },
            upsert=True
        )
    except Exception as e:
        print(f"‚ùå Erro ao salvar conversa no MongoDB para {contact_id}: {e}")

def load_conversation_from_db(contact_id):
    """Carrega o hist√≥rico de uma conversa do MongoDB, se existir."""
    try:
        result = conversation_collection.find_one({'_id': contact_id})
        if result:
            print(f"üß† Hist√≥rico anterior encontrado e carregado para {contact_id}.")
            return result
    except Exception as e:
        print(f"‚ùå Erro ao carregar conversa do MongoDB para {contact_id}: {e}")
    return None

def gerar_resposta_ia(contact_id, sender_name, user_message, known_customer_name, contact_phone):
    """
    Gera uma resposta usando a IA, com l√≥gica robusta de cache e fallback para o banco de dados.
    """
    global modelo_ia, conversations_cache

    if not modelo_ia:
        return "Desculpe, estou com um problema interno (modelo IA n√£o carregado)."

    cached_session_data = conversations_cache.get(contact_id)

    if cached_session_data:
        chat_session = cached_session_data['ai_chat_session']
        customer_name_in_cache = cached_session_data.get('customer_name')
        print(f"üß† Sess√£o para {contact_id} encontrada no cache. Nome em cache: {customer_name_in_cache}")

        # --- CORRE√á√ÉO DE AMN√âSIA (BUG GABRIEL/DANI) ---
        # Compara o nome do DB (known_customer_name) com o nome do cache (customer_name_in_cache)
        if known_customer_name and customer_name_in_cache != known_customer_name:
            print(f"üîÑ Sincronizando nome no cache: de '{customer_name_in_cache}' para '{known_customer_name}'")
            conversations_cache[contact_id]['customer_name'] = known_customer_name
            customer_name_in_cache = known_customer_name
        # --- FIM DA CORRE√á√ÉO ---
    else:
        print(f"‚ö†Ô∏è Sess√£o para {contact_id} n√£o encontrada no cache. Reconstruindo...")
        
        horario_atual = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # --- 1. L√ìGICA DE NOME (Mantida como voc√™ pediu) ---
        prompt_name_instruction = ""
        final_user_name_for_prompt = ""
        
        if known_customer_name:
            final_user_name_for_prompt = known_customer_name
            prompt_name_instruction = f"O nome do usu√°rio com quem voc√™ est√° falando √©: {final_user_name_for_prompt}. Trate-o por este nome."
        else:
            final_user_name_for_prompt = sender_name
            # Esta √© a sua regra de interven√ß√£o, que voc√™ queria manter
            prompt_name_instruction =  f"""
            REGRA CR√çTICA - CAPTURA DE NOME INTELIGENTE (PRIORIDADE M√ÅXIMA):
             Seu nome √© {{Lyra}} e voc√™ √© atendente da {{Marmitaria Sabor do Dia}}.
             Seu primeiro objetivo √© sempre descobrir o nome real do cliente, pois o nome de contato ('{sender_name}') pode ser um apelido. No entanto, voc√™ deve fazer isso de forma natural.
             Se apresente e apresente a empresa de maneira curta e profissional.

             1. Se a primeira mensagem do cliente for um simples cumprimento (ex: "oi", "boa noite"), pe√ßa o nome dele de forma direta e educada.

             2. Se a primeira mensagem do cliente j√° contiver uma pergunta (ex: "oi, qual o pre√ßo?", "quero saber como funciona"), voc√™ deve:
                - Primeiro, acalmar o cliente dizendo que j√° vai responder.
                - Em seguida, pe√ßa o nome para personalizar o atendimento.
                - **IMPORTANTE**: Voc√™ deve guardar a pergunta original do cliente na mem√≥ria.

             3. Quando o cliente responder com o nome dele (ex: "Meu nome √© Marcos"), sua pr√≥xima resposta DEVE OBRIGATORIAMENTE:
                - Come√ßar com a tag: `[NOME_CLIENTE]O nome do cliente √©: [Nome Extra√≠do].`
                - Agradecer ao cliente pelo nome.
                - **RESPONDER IMEDIATAMENTE √† pergunta original que ele fez no in√≠cio da conversa.** N√£o o fa√ßa perguntar de novo.

             EXEMPLO DE FLUXO IDEAL:
             Cliente: "boa noite, queria saber o pre√ßo ?"
             Voc√™: "Boa noite! Claro, j√° te passo os detalhes. Para que nosso atendimento fique mais pr√≥ximo, como posso te chamar?"
             Cliente: "pode me chamar de Marcos"
             Sua Resposta: "[NOME_CLIENTE]O nome do cliente √©: Marcos. Prazer em conhec√™-lo, Marcos! Os detalhes s√£o ..."
            """
        # --- FIM DA L√ìGICA DE NOME ---

        # --- L√≥gica do Prompt de Bifurca√ß√£o ---
        prompt_bifurcacao = ""
        if BIFURCACAO_ENABLED:
            prompt_bifurcacao = f"""
            =====================================================
            ‚öôÔ∏è MODO DE BIFURCA√á√ÉO DE PEDIDOS (PRIORIDADE ALTA)
            =====================================================
            Esta √© a sua principal fun√ß√£o. Voc√™ DEVE seguir este fluxo para CADA pedido.

            1.  **MISS√ÉO:** Voc√™ DEVE preencher TODOS os campos do "Gabarito de Pedido" abaixo.
            2.  **CARD√ÅPIO:** Use as informa√ß√µes do card√°pio para informar o cliente e calcular os valores.
            3.  **COLETA:** Fa√ßa perguntas UMA de cada vez. Seja persistente. 
                **NOVO: Voc√™ DEVE perguntar se o pedido √© para ENTREGA ou RETIRADA NO LOCAL.**
            4.  **TELEFONE:** O campo "telefone_contato" J√Å EST√Å PREENCHIDO. √â {contact_phone}. N√ÉO pergunte o telefone ao cliente.
            5.  **C√ÅLCULO:** Voc√™ DEVE calcular o `valor_total` somando os itens do pedido, bebidas e a `taxa_entrega` 
                **(APENAS se o tipo_pedido for 'Entrega'. Se for 'Retirada', a taxa √© R$ 0,00).**
            6.  **CONFIRMA√á√ÉO (LOOP OBRIGAT√ìRIO):** Ao ter TODOS os campos, voc√™ DEVE apresentar um RESUMO COMPLETO ao cliente (incluindo o `valor_total` calculado) e perguntar "Confirma o pedido?".
            7.  **EDI√á√ÉO (LOOP OBRIGAT√ìRIO):** Se o cliente quiser alterar (ex: "quero tirar o feijao", "adicione uma coca"), voc√™ DEVE:
                a. Ajustar o gabarito (ex: adicionar em 'observacoes', alterar 'bebidas', alterar 'pedido_completo').
                b. RECALCULAR o `valor_total`.
                c. Apresentar o NOVO resumo completo e perguntar "Confirma o pedido?" novamente.
            8.  **ENVIO (A√á√ÉO CR√çTICA):** Quando o cliente responder "sim", "confirmo", "pode enviar", ou algo positivo, sua resposta DEVE, OBRIGATORIAMENTE E SEM EXCE√á√ÉO, come√ßar com a tag [PEDIDO_CONFIRMADO] e ser seguida por um objeto JSON V√ÅLIDO contendo o gabarito.

            --- GABARITO DE PEDIDO (DEVE SER PREENCHIDO) ---
            {{
              "nome_cliente": "...", (Use o 'known_customer_name' ou o nome capturado)
              "tipo_pedido": "...", (Deve ser "Entrega" ou "Retirada")
              "endereco_completo": "...", (Se 'Retirada', preencha com 'Retirada no Local')
              "telefone_contato": "{contact_phone}", (J√Å PREENCHIDO)
              "pedido_completo": "...", (Lista de todos os itens, ex: "1 Marmita G, 2 Marmitas M (1 sem feij√£o), 1 Marmita P")
              "bebidas": "...", (ex: "1 Coca-Cola 2L", ou "Nenhuma")
              "forma_pagamento": "...", (ex: "Pix", "Cart√£o na entrega", "Dinheiro (troco para R$ 100)")
              "observacoes": "...", (ex: "1 das marmitas m√©dias sem feij√£o", "Mandar sach√™s de ketchup", ou "Nenhuma")
              "valor_total": "..." (O valor total calculado por voc√™, incluindo a taxa de entrega SE APLIC√ÅVEL)
            }}
            --- FIM DO GABARITO ---
            """
        else:
            prompt_bifurcacao = "O plano de Bifurca√ß√£o (envio para cozinha) n√£o est√° ativo."
        
        prompt_inicial = f"""
            A data e hora atuais s√£o: {horario_atual}.
            {prompt_name_instruction}
            
            =====================================================
            üè∑Ô∏è IDENTIDADE DO ATENDENTE
            =====================================================
            nome: {{Lyra}}
            fun√ß√£o: {{Atendente de restaurante (delivery)}} 
            papel: {{Voc√™ deve atender o cliente, apresentar o card√°pio, anotar o pedido completo, calcular o valor total e confirmar a entrega.}}

            =====================================================
            üè¢ IDENTIDADE DA EMPRESA
            =====================================================
            nome da empresa: {{Marmitaria Sabor do Dia}}
            hor√°rio de atendimento: {{Segunda a S√°bado, das 11:00 √†s 14:00}}
            
            =====================================================
            üç≤ CARD√ÅPIO E PRE√áOS (BASE DO PEDIDO)
            =====================================================
            
            --- PRATO DO DIA (Exemplo) ---
            Hoje temos: {{Strogonoff de Frango}}
            Acompanhamentos: {{Arroz branco, Feij√£o, Batata palha e Salada de alface e tomate.}}

            --- TAMANHOS E VALORES (Marmitas) ---
            - Marmita Pequena (P): {{R$ 15,00}}
            - Marmita M√©dia (M): {{R$ 18,00}}
            - Marmita Grande (G): {{R$ 22,00}}

            --- ü•§ BEBIDAS ---
            - Coca-Cola Lata (350ml): {{R$ 5,00}}
            - Guaran√° Antartica Lata (350ml): {{R$ 5,00}}
            - √Ågua Mineral (sem g√°s): {{R$ 3,00}}
            - Suco de Laranja (natural 500ml): {{R$ 8,00}}

            --- üõµ TAXA DE ENTREGA ---
            - Taxa de Entrega Fixa: {{R$ 6,00}} (Use este valor para C√ÅLCULO do valor total APENAS PARA ENTREGAS)
            - Pedidos para Retirada no Local: {{R$ 0,00}} (n√£o h√° taxa)

            {prompt_bifurcacao} 

            =====================================================
            üß≠ COMPORTAMENTO E REGRAS DE ATENDIMENTO
            =====================================================
            - FOCO TOTAL: Seu primeiro objetivo √© capturar o nome do cliente. Seu segundo objetivo √© preencher o "Gabarito de Pedido" e confirmar.
            - n√£o deve fazer: N√£o inventar pratos ou pre√ßos. N√£o falar sobre "IA" ou "Chatbot". Voc√™ √© uma ATENDENTE HUMANA (Lyra).
            
            =====================================================
            PRONTO PARA ATENDER O CLIENTE
            =====================================================
            """

        # --- CORRE√á√ÉO DE CONFLITO ---
        # A mensagem inicial do bot agora √© neutra. Ela n√£o tenta vender
        # e deixa a "REGRA CR√çTICA" funcionar primeiro.
        convo_start = [
            {'role': 'user', 'parts': [prompt_inicial]},
            {'role': 'model', 'parts': [f"Entendido. Eu sou Lyra, atendente da Marmitaria Sabor do Dia. Minha prioridade √© capturar o nome do cliente ({final_user_name_for_prompt}) e depois anotar o pedido. Estou pronta."]}
        ]

        loaded_conversation = load_conversation_from_db(contact_id)
        old_history = []
        if loaded_conversation and 'history' in loaded_conversation:
            old_history = [msg for msg in loaded_conversation['history'] if not msg['parts'][0].strip().startswith("A data e hora atuais s√£o:")]
        
        chat_session = modelo_ia.start_chat(history=convo_start + old_history)
        
        conversations_cache[contact_id] = {
            'ai_chat_session': chat_session, 
            'name': sender_name, 
            'customer_name': known_customer_name
        }
        customer_name_in_cache = known_customer_name

    # --- FIM DA L√ìGICA DE CACHE/RECONSTRU√á√ÉO ---

    try:
        print(f"Enviando para a IA: '{user_message}' (De: {sender_name})")
        
        try:
            input_tokens = modelo_ia.count_tokens(chat_session.history + [{'role':'user', 'parts': [user_message]}]).total_tokens
        except Exception as e:
            print(f"Aviso: count_tokens falhou, continuando sem contar. Erro: {e}")
            input_tokens = 0

        resposta = chat_session.send_message(user_message)
        
        try:
            output_tokens = modelo_ia.count_tokens(resposta.text).total_tokens
        except Exception as e:
            print(f"Aviso: count_tokens (sa√≠da) falhou. Erro: {e}")
            output_tokens = 0
            
        total_tokens_na_interacao = input_tokens + output_tokens
        
        if total_tokens_na_interacao > 0:
             print(f"üìä Consumo de Tokens: Entrada={input_tokens}, Sa√≠da={output_tokens}, Total={total_tokens_na_interacao}")
        
        ai_reply = resposta.text

        if ai_reply.strip().startswith("[NOME_CLIENTE]"):
            print("üìù Tag [NOME_CLIENTE] detectada. Extraindo e salvando nome...")
            try:
                full_response_part = ai_reply.split("O nome do cliente √©:")[1].strip()
                extracted_name = full_response_part.split('.')[0].strip()
                start_of_message_index = full_response_part.find(extracted_name) + len(extracted_name)
                ai_reply = full_response_part[start_of_message_index:].lstrip('.!?, ').strip()

                conversation_collection.update_one(
                    {'_id': contact_id},
                    {'$set': {'customer_name': extracted_name}},
                    upsert=True
                )
                # --- CORRE√á√ÉO DE AMN√âSIA ---
                # Garante que o cache local seja atualizado IMEDIATAMENTE com o nome novo
                if contact_id in conversations_cache:
                    conversations_cache[contact_id]['customer_name'] = extracted_name
                customer_name_in_cache = extracted_name
                # --- FIM DA CORRE√á√ÉO ---
                print(f"‚úÖ Nome '{extracted_name}' salvo para o cliente {contact_id}.")

            except Exception as e:
                print(f"‚ùå Erro ao extrair o nome da tag: {e}")
                ai_reply = ai_reply.replace("[NOME_CLIENTE]", "").strip()

        save_conversation_to_db(contact_id, sender_name, customer_name_in_cache, chat_session, total_tokens_na_interacao)
        
        return ai_reply
    
    except Exception as e:
        print(f"‚ùå Erro ao comunicar com a API do Gemini: {e}")
        if contact_id in conversations_cache:
            del conversations_cache[contact_id]
        return "Tive um pequeno problema para processar sua mensagem e precisei reiniciar nossa conversa. Voc√™ poderia repetir, por favor?"
    
def transcrever_audio_gemini(caminho_do_audio):
    """
    Envia um arquivo de √°udio para a API do Gemini e retorna a transcri√ß√£o em texto.
    """
    global modelo_ia 

    if not modelo_ia:
        print("‚ùå Modelo de IA n√£o inicializado. Imposs√≠vel transcrever.")
        return None

    print(f"üé§ Enviando √°udio '{caminho_do_audio}' para transcri√ß√£o no Gemini...")
    try:
        audio_file = genai.upload_file(
            path=caminho_do_audio, 
            mime_type="audio/ogg" # O formato padr√£o da Evolution
        )
        
        response = modelo_ia.generate_content(["Por favor, transcreva o √°udio a seguir.", audio_file])
        genai.delete_file(audio_file.name)
        
        if response.text:
            print(f"‚úÖ Transcri√ß√£o recebida: '{response.text}'")
            return response.text
        else:
            print("‚ö†Ô∏è A IA n√£o retornou texto para o √°udio. Pode ser um √°udio sem falas.")
            return None
    except Exception as e:
        print(f"‚ùå Erro ao transcrever √°udio com Gemini: {e}")
        return None

def send_whatsapp_message(number, text_message):
    """Envia uma mensagem de texto para um n√∫mero via Evolution API."""
    # O nome da sua inst√¢ncia
    INSTANCE_NAME = "chatbot" 
    
    full_url = f"{EVOLUTION_API_URL}/message/sendText/{INSTANCE_NAME}"

    # A sua fun√ß√£o base j√° espera o JID completo (ex: 55...@s.whatsapp.net),
    # mas a API da evolution quer o n√∫mero limpo. A sua fun√ß√£o j√° trata isso.
    clean_number = number.split('@')[0]
    payload = {"number": clean_number, "textMessage": {"text": text_message}}
    headers = {"apikey": EVOLUTION_API_KEY, "Content-Type": "application/json"}
    try:
        print(f"‚úÖ Enviando resposta para a URL: {full_url} (Destino: {clean_number})")
        response = requests.post(full_url, json=payload, headers=headers)
        response.raise_for_status()
        print(f"‚úÖ Resposta da IA enviada com sucesso para {clean_number}\n")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erro ao enviar mensagem para {clean_number}: {e}")

def gerar_e_enviar_relatorio_semanal():
    """Calcula um RESUMO do uso de tokens e envia por e-mail usando SendGrid."""
    print(f"üóìÔ∏è Gerando relat√≥rio semanal para o cliente: {CLIENT_NAME}...")
    
    SENDGRID_API_KEY = os.environ.get('SENDGRID_API_KEY')
    EMAIL_RELATORIOS = os.environ.get('EMAIL_RELATORIOS')

    if not all([SENDGRID_API_KEY, EMAIL_RELATORIOS]):
        print("‚ö†Ô∏è Vari√°veis SENDGRID_API_KEY e EMAIL_RELATORIOS n√£o configuradas. Relat√≥rio n√£o pode ser enviado.")
        return

    hoje = datetime.now()
    
    try:
        usuarios_do_bot = list(conversation_collection.find({}))
        numero_de_contatos = len(usuarios_do_bot)
        total_geral_tokens = 0
        media_por_contato = 0

        if numero_de_contatos > 0:
            for usuario in usuarios_do_bot:
                total_geral_tokens += usuario.get('total_tokens_consumed', 0)
            media_por_contato = total_geral_tokens / numero_de_contatos
        
        corpo_email_texto = f"""
        Relat√≥rio de Consumo Acumulado do Cliente: '{CLIENT_NAME}'
        Data do Relat√≥rio: {hoje.strftime('%d/%m/%Y')}

        --- RESUMO GERAL DE USO ---

        üë§ N√∫mero de Contatos √önicos: {numero_de_contatos}
        üî• Consumo Total de Tokens (Acumulado): {total_geral_tokens}
        üìä M√©dia de Tokens por Contato: {media_por_contato:.0f}

        ---------------------------
        Atenciosamente,
        Seu Sistema de Monitoramento.
        """

        message = Mail(
            from_email=EMAIL_RELATORIOS,
            to_emails=EMAIL_RELATORIOS,
            subject=f"Relat√≥rio Semanal de Tokens - {CLIENT_NAME} - {hoje.strftime('%d/%m')}",
            plain_text_content=corpo_email_texto
        )
        
        sendgrid_client = SendGridAPIClient(SENDGRID_API_KEY)
        response = sendgrid_client.send(message)
        
        if response.status_code == 202:
             print(f"‚úÖ Relat√≥rio semanal para '{CLIENT_NAME}' enviado com sucesso via SendGrid!")
        else:
             print(f"‚ùå Erro ao enviar e-mail via SendGrid. Status: {response.status_code}. Body: {response.body}")

    except Exception as e:
        print(f"‚ùå Erro ao gerar ou enviar relat√≥rio para '{CLIENT_NAME}': {e}")

app = Flask(__name__)

processed_messages = set() 

@app.route('/webhook', methods=['POST'])
def receive_webhook():
    """Recebe mensagens do WhatsApp enviadas pela Evolution API."""
    data = request.json
    print(f"üì¶ DADO BRUTO RECEBIDO NO WEBHOOK: {data}")

    # --- L√≥gica de filtro de evento (Mantida da sua base) ---
    event_type = data.get('event')
    
    if event_type != 'messages.upsert':
        print(f"‚û°Ô∏è ¬†Ignorando evento: {event_type} (n√£o √© uma nova mensagem)")
        return jsonify({"status": "ignored_event_type"}), 200
    # --- FIM DA CORRE√á√ÉO ---

    try:
        message_data = data.get('data', {}) 
        if not message_data:
            print("‚û°Ô∏è ¬†Evento 'messages.upsert' sem 'data'. Ignorando.")
            return jsonify({"status": "ignored_no_data"}), 200
            
        key_info = message_data.get('key', {})

        # --- 6. L√ìGICA DE 'fromMe' MODIFICADA ---
        # (Removemos a checagem do RESPONSIBLE_NUMBER)
        if key_info.get('fromMe'):
            print(f"‚û°Ô∏è ¬†Mensagem do pr√≥prio bot ignorada.")
            return jsonify({"status": "ignored_from_me"}), 200

        message_id = key_info.get('id')
        if not message_id:
            return jsonify({"status": "ignored_no_id"}), 200

        if message_id in processed_messages:
            print(f"‚ö†Ô∏è Mensagem {message_id} j√° processada, ignorando.")
            return jsonify({"status": "ignored_duplicate"}), 200
        processed_messages.add(message_id)
        if len(processed_messages) > 1000:
            processed_messages.clear()

        # --- Inicia o Buffer (Mantido da sua base) ---
        threading.Thread(target=handle_message_buffering, args=(message_data,)).start()
        return jsonify({"status": "received"}), 200

    except Exception as e:
        print(f"‚ùå Erro inesperado no webhook: {e}")
        print("DADO QUE CAUSOU ERRO:", data)
        return jsonify({"status": "error"}), 500

@app.route('/', methods=['GET'])
def health_check():
    return "Estou vivo! (Marmitaria Bot)", 200 # Mensagem de sa√∫de atualizada

# <<< FUN√á√ÉO handle_responsible_command REMOVIDA >>>
# (N√£o √© necess√°ria, pois n√£o h√° interven√ß√£o humana)

def handle_message_buffering(message_data):
    """
    Esta fun√ß√£o recebe a mensagem, a coloca em um buffer e gerencia um timer.
    (Mantida 100% da sua base)
    """
    try:
        key_info = message_data.get('key', {})
        sender_number_full = key_info.get('senderPn') or key_info.get('participant') or key_info.get('remoteJid')

        if not sender_number_full or sender_number_full.endswith('@g.us'):
            return

        clean_number = sender_number_full.split('@')[0]
        
        user_message_content = None
        message = message_data.get('message', {})
        
        if message.get('conversation'):
            user_message_content = message['conversation']
        elif message.get('extendedTextMessage'):
            user_message_content = message['extendedTextMessage'].get('text')
        elif message.get('audioMessage') and message.get('base64'):
            message_id = key_info.get('id')
            print(f"üé§ Mensagem de √°udio recebida de {clean_number}. Aguardando timer para transcrever.")
            audio_base64 = message['base64']
            audio_data = base64.b64decode(audio_base64)
            temp_audio_path = f"/tmp/audio_{clean_number}_{message_id}.ogg"
            with open(temp_audio_path, 'wb') as f:
                f.write(audio_data)
            user_message_content = transcrever_audio_gemini(temp_audio_path)
            os.remove(temp_audio_path)
            if not user_message_content:
                send_whatsapp_message(sender_number_full, "Desculpe, n√£o consegui entender o √°udio. Pode tentar novamente? üéß")
                return
        
        if not user_message_content:
            return

        # Adiciona a nova mensagem ao buffer do usu√°rio
        if clean_number not in message_buffer:
            message_buffer[clean_number] = []
        message_buffer[clean_number].append(user_message_content)
        print(f"üì• Mensagem de {clean_number} adicionada ao buffer. Buffer atual: {message_buffer[clean_number]}")

        # Se j√° existe um timer para este usu√°rio, cancele-o
        if clean_number in message_timers:
            message_timers[clean_number].cancel()

        # Inicia um novo timer de 10 segundos
        timer = threading.Timer(10.0, _trigger_ai_processing, args=[message_data])
        message_timers[clean_number] = timer
        timer.start()
        print(f"‚è≥ Timer de 10s iniciado/reiniciado para {clean_number}.")

    except Exception as e:
        print(f"‚ùå Erro ao gerenciar buffer da mensagem: {e}")

# --- 7. FUN√á√ÉO _trigger_ai_processing MODIFICADA ---
def _trigger_ai_processing(message_data):
    """
    Esta fun√ß√£o √© chamada pelo timer. Ela pega todas as mensagens do buffer,
    junta-as e envia para a IA.
    Agora usa a l√≥gica de BIFURCA√á√ÉO ao inv√©s de interven√ß√£o.
    """
    key_info = message_data.get('key', {})
    sender_number_full = key_info.get('senderPn') or key_info.get('participant') or key_info.get('remoteJid')
    clean_number = sender_number_full.split('@')[0]
    sender_name_from_wpp = message_data.get('pushName') or 'Cliente'
    
    if clean_number not in message_buffer:
        return
        
    full_user_message = "\n".join(message_buffer[clean_number])
    
    del message_buffer[clean_number]
    del message_timers[clean_number]
    
    print(f"‚è∞ Timer finalizado! Processando mensagem completa de {clean_number}: '{full_user_message}'")

    # <<< REMOVIDO: Bloco de 'handle_responsible_command' >>>
    # <<< REMOVIDO: Bloco de checagem 'intervention_active' >>>

    conversation_status = conversation_collection.find_one({'_id': clean_number})
    known_customer_name = conversation_status.get('customer_name') if conversation_status else None
    
    # --- ATUALIZADO: Passa o 'clean_number' como 'contact_phone' ---
    ai_reply = gerar_resposta_ia(clean_number, sender_name_from_wpp, full_user_message, known_customer_name, clean_number)

    # --- 8. L√ìGICA DE BIFURCA√á√ÉO (DA MARMITARIA) ---
    if BIFURCACAO_ENABLED and ai_reply and ai_reply.strip().startswith("[PEDIDO_CONFIRMADO]"):
        print(f"üì¶ Tag [PEDIDO_CONFIRMADO] detectada. Processando e bifurcando pedido para {clean_number}...")
        try:
            # 1. Isolar o JSON do resto da mensagem
            json_start = ai_reply.find('{')
            json_end = ai_reply.rfind('}') + 1

            if json_start == -1 or json_end == 0:
                raise ValueError("JSON de pedido n√£o encontrado ap√≥s a tag.")

            json_string = ai_reply[json_start:json_end]

            # 2. Isolar a mensagem de resposta para o cliente
            remaining_reply = ai_reply[json_end:].strip()
            if not remaining_reply:
                remaining_reply = "Seu pedido foi confirmado e enviado para a cozinha! üòã" # Fallback

            # 3. Parsear o JSON
            order_data = json.loads(json_string)

            # 4. Formatar as mensagens de bifurca√ß√£o
            # Mensagem para a COZINHA (Completa)
            msg_cozinha = f"""
            --- üç≥ NOVO PEDIDO (COZINHA) üç≥ ---
            
            Cliente: {order_data.get('nome_cliente', 'N/A')}
            Telefone: {order_data.get('telefone_contato', 'N/A')}
            Endere√ßo: {order_data.get('endereco_completo', 'N/A')}
            
            --- PEDIDO ---
            {order_data.get('pedido_completo', 'N/A')}
            
            --- BEBIDAS ---
            {order_data.get('bebidas', 'N/A')}
            
            --- OBSERVA√á√ïES ---
            {order_data.get('observacoes', 'N/A')}
            
            Forma de Pagto: {order_data.get('forma_pagamento', 'N/A')}
            Valor Total: {order_data.get('valor_total', 'N/A')}
            """

            # Mensagem para o MOTOBOY (Parcial)
            msg_motoboy = f"""
            --- üõµ NOVA ENTREGA (MOTOBOY) üõµ ---
            
            Cliente: {order_data.get('nome_cliente', 'N/A')}
            Telefone: {order_data.get('telefone_contato', 'N/A')}
            Endere√ßo: {order_data.get('endereco_completo', 'N/A')}
            
            Forma de Pagto: {order_data.get('forma_pagamento', 'N/A')}
            Valor Total: {order_data.get('valor_total', 'N/A')}
            """

            # 5. Enviar as mensagens (em threads para n√£o bloquear a resposta)
            # A sua fun√ß√£o send_whatsapp_message espera o JID completo (com @s.whatsapp.net)
            threading.Thread(target=send_whatsapp_message, args=(f"{COZINHA_WPP_NUMBER}@s.whatsapp.net", msg_cozinha.strip())).start()
            threading.Thread(target=send_whatsapp_message, args=(f"{MOTOBOY_WPP_NUMBER}@s.whatsapp.net", msg_motoboy.strip())).start()

            print(f"‚úÖ Pedido bifurcado com sucesso para {COZINHA_WPP_NUMBER} e {MOTOBOY_WPP_NUMBER}.")

            # 6. Atualiza a resposta para o cliente
            ai_reply = remaining_reply

        except Exception as e:
            print(f"‚ùå Erro ao processar bifurca√ß√£o [PEDIDO_CONFIRMADO]: {e}")
            ai_reply = ai_reply.replace("[PEDIDO_CONFIRMADO]", "").strip()
            if '{' in ai_reply and '}' in ai_reply:
                ai_reply = "Tive um problema ao enviar seu pedido para a cozinha. Pode confirmar os dados novamente, por favor? (Erro interno: JSON_PARSE)"
        
        # Envia a resposta final (seja de sucesso ou erro) para o cliente
        print(f"ü§ñ Resposta da IA para {sender_name_from_wpp}: {ai_reply}")
        send_whatsapp_message(sender_number_full, ai_reply)

    elif ai_reply:
        # Se n√£o for um pedido, √© uma conversa normal
        print(f"ü§ñ Resposta da IA para {sender_name_from_wpp}: {ai_reply}")
        send_whatsapp_message(sender_number_full, ai_reply)
    # --- FIM DO BLOCO DE BIFURCA√á√ÉO ---


if __name__ == '__main__':
    if modelo_ia:
        print("\n=============================================")
        print("   CHATBOT WHATSAPP COM IA INICIADO")
        # --- 9. MENSAGEM DE START ATUALIZADA ---
        print(f"   CLIENTE: {CLIENT_NAME}")
        if not BIFURCACAO_ENABLED:
            print("   AVISO: 'COZINHA_WPP_NUMBER' ou 'MOTOBOY_WPP_NUMBER' n√£o configurados. O recurso de bifurca√ß√£o est√° DESATIVADO.")
        else:
            print(f"   Bifurca√ß√£o ATIVA. Cozinha: {COZINHA_WPP_NUMBER} | Motoboy: {MOTOBOY_WPP_NUMBER}")
        print("=============================================")
        print("Servidor aguardando mensagens no webhook...")

        scheduler = BackgroundScheduler(daemon=True, timezone='America/Sao_Paulo') 
        scheduler.add_job(gerar_e_enviar_relatorio_semanal, 'cron', day_of_week='sun', hour=8, minute=0)
        scheduler.start()
        print("‚è∞ Agendador de relat√≥rios iniciado. O relat√≥rio ser√° enviado todo Domingo √†s 08:00.")
        
        import atexit
        atexit.register(lambda: scheduler.shutdown())
        
        # O Fly.io vai injetar a vari√°vel PORT, mas 8000 √© um bom padr√£o
        port = int(os.environ.get("PORT", 8000))
        app.run(host='0.0.0.0', port=port)
    else:
        print("\nEncerrando o programa devido a erros na inicializa√ß√£o.")