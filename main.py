import google.generativeai as genai
import requests
import os
import json  # <--- ADICIONADO: Necess√°rio para processar o gabarito do pedido
import threading
from flask import Flask, request, jsonify
from datetime import datetime
from dotenv import load_dotenv
import base64
from pymongo import MongoClient
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail
from apscheduler.schedulers.background import BackgroundScheduler

CLIENT_NAME = "Neuro Solu√ß√µes em Tecnologia"
load_dotenv()
EVOLUTION_API_URL = os.environ.get("EVOLUTION_API_URL")
EVOLUTION_API_KEY = os.environ.get("EVOLUTION_API_KEY", "1234")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MONGO_DB_URI = os.environ.get("MONGO_DB_URI")

# --- NOVO: Vari√°veis para o Plano de Bifurca√ß√£o ---
# (Adicione estes no seu arquivo .env)
COZINHA_WPP_NUMBER = "554898389781"
MOTOBOY_WPP_NUMBER = "554499242532"

# Flag para saber se a funcionalidade est√° ativa
BIFURCACAO_ENABLED = bool(COZINHA_WPP_NUMBER and MOTOBOY_WPP_NUMBER)
if BIFURCACAO_ENABLED:
    print(f"‚úÖ Plano de Bifurca√ß√£o ATIVO. Cozinha: {COZINHA_WPP_NUMBER}, Motoboy: {MOTOBOY_WPP_NUMBER}")
else:
    print("‚ö†Ô∏è Plano de Bifurca√ß√£o INATIVO. (Configure COZINHA_WPP_NUMBER e MOTOBOY_WPP_NUMBER no .env)")
# --- FIM DA NOVA SE√á√ÉO ---

try:
    client = MongoClient(MONGO_DB_URI)
    db_name = CLIENT_NAME.lower().replace(" ", "_").replace("-", "_")
    db = client[db_name]  # Conecta ao banco de dados espec√≠fico do cliente
    conversation_collection = db.conversations
    print(f"‚úÖ Conectado ao MongoDB para o cliente: '{CLIENT_NAME}' no banco de dados '{db_name}'")
except Exception as e:
    print(f"‚ùå ERRO: N√£o foi poss√≠vel conectar ao MongoDB. Erro: {e}")

if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
    except Exception as e:
        print(f"AVISO: A chave de API do Google n√£o foi configurada corretamente. Erro: {e}")
else:
    print("AVISO: A vari√°vel de ambiente GEMINI_API_KEY n√£o foi definida.")

# Cache para conversas ativas (para evitar ler o DB a cada mensagem)
conversations_cache = {}

modelo_ia = None
try:
    modelo_ia = genai.GenerativeModel('gemini-2.5-flash') # Recomendo usar o 1.5-flash
    print("‚úÖ Modelo do Gemini inicializado com sucesso.")
except Exception as e:
    print(f"‚ùå ERRO: N√£o foi poss√≠vel inicializar o modelo do Gemini. Verifique sua API Key. Erro: {e}")


def save_conversation_to_db(contact_id, sender_name, customer_name, chat_session, tokens_used):
    """Salva o hist√≥rico, nomes e atualiza a contagem de tokens no MongoDB."""
    try:
        history_list = [
            {'role': msg.role, 'parts': [part.text for part in msg.parts]}
            for msg in chat_session.history
        ]

        update_payload = {
            'sender_name': sender_name,  # Nome do contato no WhatsApp
            'history': history_list,
            'last_interaction': datetime.now()
        }
        # Adiciona o nome real do cliente ao payload se ele for conhecido
        if customer_name:
            update_payload['customer_name'] = customer_name

        conversation_collection.update_one(
            {'_id': contact_id},
            {
                '$set': update_payload,
                '$inc': {
                    'total_tokens_consumed': tokens_used
                }
            },
            upsert=True
        )
    except Exception as e:
        print(f"‚ùå Erro ao salvar conversa no MongoDB para {contact_id}: {e}")


def load_conversation_from_db(contact_id):
    """Carrega o hist√≥rico de uma conversa do MongoDB, se existir."""
    try:
        result = conversation_collection.find_one({'_id': contact_id})
        if result:
            print(f"üß† Documento da conversa encontrado e carregado para {contact_id}.")
            return result
    except Exception as e:
        print(f"‚ùå Erro ao carregar conversa do MongoDB para {contact_id}: {e}")
    return None


# --- ATUALIZADO: Adicionado 'contact_phone' ---
def gerar_resposta_ia(contact_id, sender_name, user_message, known_customer_name, contact_phone):
    """
    Gera uma resposta usando a IA, com l√≥gica para perguntar e salvar o nome do cliente.
    """
    global modelo_ia, conversations_cache

    if not modelo_ia:
        return "Desculpe, estou com um problema interno (modelo IA n√£o carregado)."

    if contact_id not in conversations_cache:
        horario_atual = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        prompt_name_instruction = ""
        final_user_name_for_prompt = ""

        # --- MUDAN√áA DE L√ìGICA DE NOME ---
        # Para um restaurante, √© mais r√°pido e direto j√° tratar pelo nome do WPP
        # e s√≥ confirmar se o pedido for para "outra pessoa".
        if known_customer_name:
            final_user_name_for_prompt = known_customer_name
            prompt_name_instruction = f"O nome do usu√°rio com quem voc√™ est√° falando √©: {final_user_name_for_prompt}. Trate-o por este nome."
        else:
            # Se n√£o salvou o nome ainda, usa o nome do WhatsApp
            final_user_name_for_prompt = sender_name
            prompt_name_instruction = f"""
            REGRA DE NOME (BAIXA PRIORIDADE):
            Seu nome nome: {{Lyra}} voc√™ √© atendente da {{Marmitaria Sabor do Dia}}.
            O nome de contato do cliente √© '{sender_name}'. Use este nome para falar com ele (ex: "Ol√°, {sender_name}!").
            Se, durante o pedido, o cliente disser que o pedido √© para OUTRA pessoa (ex: "√© para o meu marido, Jo√£o"),
            voc√™ DEVE usar a tag [NOME_CLIENTE] para salvar o nome correto.
            
            EXEMPLO DE CAPTURA:
            Cliente: "oi, quero uma marmita"
            Voc√™: "Ol√°, {sender_name}! Claro, para quem ser√° o pedido?"
            Cliente: "√© para mim mesmo"
            Voc√™: "Perfeito, {sender_name}. Qual o tamanho da marmita... (continua o pedido)"
            
            EXEMPLO DE CAPTURA CORRETA (OUTRA PESSOA):
            Cliente: "oi, quero uma marmita"
            Voc√™: "Ol√°, {sender_name}! Claro, para quem ser√° o pedido?"
            Cliente: "√© para minha filha, Maria"
            Sua Resposta: "[NOME_CLIENTE]O nome do cliente √©: Maria. Entendido! O pedido ser√° para a Maria. Qual o tamanho da marmita... (continua o pedido)"
            """

        # --- NOVO: L√≥gica do Prompt de Bifurca√ß√£o ---
        prompt_bifurcacao = ""
        if BIFURCACAO_ENABLED:
            prompt_bifurcacao = f"""
            =====================================================
            ‚öôÔ∏è MODO DE BIFURCA√á√ÉO DE PEDIDOS (PRIORIDADE ALTA)
            =====================================================
            Esta √© a sua principal fun√ß√£o. Voc√™ DEVE seguir este fluxo para CADA pedido.

            1.  **MISS√ÉO:** Voc√™ DEVE preencher TODOS os campos do "Gabarito de Pedido" abaixo.
            2.  **CARD√ÅPIO:** Use as informa√ß√µes do card√°pio para informar o cliente e calcular os valores.
            3.  **COLETA:** Fa√ßa perguntas UMA de cada vez, de forma natural, at√© ter todos os dados. Seja persistente.
            4.  **TELEFONE:** O campo "telefone_contato" J√Å EST√Å PREENCHIDO. √â {contact_phone}. N√ÉO pergunte o telefone ao cliente.
            5.  **C√ÅLCULO:** Voc√™ DEVE calcular o `valor_total` somando os itens do pedido, bebidas e a `taxa_entrega`.
            6.  **CONFIRMA√á√ÉO (LOOP OBRIGAT√ìRIO):** Ao ter TODOS os campos, voc√™ DEVE apresentar um RESUMO COMPLETO ao cliente (incluindo o `valor_total` calculado) e perguntar "Confirma o pedido?".
            7.  **EDI√á√ÉO (LOOP OBRIGAT√ìRIO):** Se o cliente quiser alterar (ex: "quero tirar o feijao", "adicione uma coca"), voc√™ DEVE:
                a. Ajustar o gabarito (ex: adicionar em 'observacoes', alterar 'bebidas').
                b. RECALCULAR o `valor_total`.
                c. Apresentar o NOVO resumo completo e perguntar "Confirma o pedido?" novamente.
            8.  **ENVIO (A√á√ÉO CR√çTICA):** Quando o cliente responder "sim", "confirmo", "pode enviar", ou algo positivo, sua resposta DEVE, OBRIGATORIAMENTE E SEM EXCE√á√ÉO, come√ßar com a tag [PEDIDO_CONFIRMADO] e ser seguida por um objeto JSON V√ÅLIDO contendo o gabarito.

            --- GABARITO DE PEDIDO (DEVE SER PREENCHIDO) ---
            {{
              "nome_cliente": "...", (Use o 'known_customer_name' ou o nome capturado)
              "endereco_completo": "...", (Rua, N√∫mero, Bairro, Cidade/Estado, Ponto de Refer√™ncia se houver)
              "telefone_contato": "{contact_phone}", (J√Å PREENCHIDO)
              "pedido_completo": "...", (Lista de todos os itens, ex: "1 Marmita G, 2 Marmitas M (1 sem feij√£o), 1 Marmita P")
              "bebidas": "...", (ex: "1 Coca-Cola 2L", ou "Nenhuma")
              "forma_pagamento": "...", (ex: "Pix", "Cart√£o na entrega", "Dinheiro (troco para R$ 100)")
              "observacoes": "...", (ex: "1 das marmitas m√©dias sem feij√£o", "Mandar sach√™s de ketchup", ou "Nenhuma")
              "valor_total": "..." (O valor total calculado por voc√™, incluindo a taxa de entrega)
            }}
            --- FIM DO GABARITO ---

            EXEMPLO DE INTERA√á√ÉO DE ENVIO CORRETA:
            Cliente: "Isso mesmo, pode confirmar."
            Sua Resposta: [PEDIDO_CONFIRMADO]{{
              "nome_cliente": "Gabriel",
              "endereco_completo": "Rua China, 0, Bairro X, Maring√°-PR",
              "telefone_contato": "{contact_phone}",
              "pedido_completo": "1 Marmita G (Strogonoff), 1 Marmita M (Strogonoff)",
              "bebidas": "1 Coca-Cola Lata",
              "forma_pagamento": "Pix",
              "observacoes": "Caprichar na batata palha.",
              "valor_total": "R$ 49,00"
            }}
            Pedido confirmado, Gabriel! üòã Estou enviando para a cozinha. O tempo de entrega √© de 40 a 50 minutos. Muito obrigada!
            """
        else:
            prompt_bifurcacao = "O plano de Bifurca√ß√£o (envio para cozinha) n√£o est√° ativo."
        # --- FIM DA NOVA SE√á√ÉO ---

        prompt_inicial = f"""
                A data e hora atuais s√£o: {horario_atual}.
                {prompt_name_instruction}
                
                =====================================================
                üè∑Ô∏è IDENTIDADE DO ATENDENTE
                =====================================================
                nome: {{Lyra}}
                sexo: {{Feminina}}
                fun√ß√£o: {{Atendente de restaurante (delivery)}} 
                papel: {{Voc√™ deve atender o cliente, apresentar o card√°pio, anotar o pedido completo, calcular o valor total e confirmar a entrega.}}

                =====================================================
                üè¢ IDENTIDADE DA EMPRESA
                =====================================================
                nome da empresa: {{Marmitaria Sabor do Dia}} (Nome Fict√≠cio, altere se necess√°rio)
                setor: {{Alimenta√ß√£o e Delivery}} 
                miss√£o: {{Entregar a melhor comida caseira da cidade, com rapidez e sabor.}}
                hor√°rio de atendimento: {{Segunda a S√°bado, das 11:00 √†s 14:00}}
                
                =====================================================
                üç≤ CARD√ÅPIO E PRE√áOS (BASE DO PEDIDO)
                =====================================================
                
                --- PRATO DO DIA (Exemplo) ---
                Hoje temos: {{Strogonoff de Frango}}
                Acompanhamentos: {{Arroz branco, Feij√£o, Batata palha e Salada de alface e tomate.}}
                (A menos que o cliente pe√ßa, todas as marmitas v√™m com todos os acompanhamentos. Ex: "sem feij√£o" deve ir em observa√ß√µes).

                --- TAMANHOS E VALORES (Marmitas) ---
                - Marmita Pequena (P): {{R$ 15,00}}
                - Marmita M√©dia (M): {{R$ 18,00}}
                - Marmita Grande (G): {{R$ 22,00}}

                --- ü•§ BEBIDAS ---
                - Coca-Cola Lata (350ml): {{R$ 5,00}}
                - Guaran√° Antartica Lata (350ml): {{R$ 5,00}}
                - √Ågua Mineral (sem g√°s): {{R$ 3,00}}
                - Suco de Laranja (natural 500ml): {{R$ 8,00}}

                --- üõµ TAXA DE ENTREGA ---
                - Taxa de Entrega Fixa: {{R$ 6,00}} (Use este valor para C√ÅLCULO do valor total)

                {prompt_bifurcacao} 

                =====================================================
                üß≠ COMPORTAMENTO E REGRAS DE ATENDIMENTO
                =====================================================
                a√ß√µes:
                - Responda sempre de forma alegre, educada e um pouco informal (use emojis üòã, üòä, üõµ).
                - Use frases curtas e diretas.
                - Mantenha sempre um tom positivo e prestativo.
                - SEJA PROATIVA: Se o cliente diz "oi", j√° pergunte se ele quer ver o card√°pio do dia.
                - FOCO TOTAL: Seu objetivo √© preencher o "Gabarito de Pedido" e confirmar a entrega.
                
                n√£o deve fazer:
                - N√£o inventar pratos ou pre√ßos que n√£o est√£o no card√°pio.
                - N√£o discutir com o cliente.
                - N√£o falar sobre "Neuro Solu√ß√µes em Tecnologia", "Planos", "IA", "Chatbot". Voc√™ √© uma ATENDENTE HUMANA (Lyra) da marmitaria.

                =====================================================
                ‚öôÔ∏è PERSONALIDADE DO ATENDENTE
                =====================================================
                - Tom de voz: {{alegre, acolhedor, prestativo}} 
                - Estilo: {{Humana, simp√°tica, vendedora (de comida)}}
                - Emojis: {{use com modera√ß√£o, para dar tom de apetite üòã}}
                
                =====================================================
                üß© EXEMPLO DE COMPORTAMENTO
                =====================================================
                Cliente: "oi boa noite"
                Atendente: "Ol√°, {final_user_name_for_prompt}! Boa noite! üòä Nosso card√°pio hoje est√° uma del√≠cia! Nosso prato do dia √© Strogonoff de Frango, acompanhado de arroz, feij√£o, batata palha e salada. Vamos pedir hoje? üòã"

                Cliente: "eu quero saber se tem marmita ai ?"
                Atendente: "Temos sim, {final_user_name_for_prompt}! √â a nossa especialidade! üòä Hoje o prato do dia √© Strogonoff de Frango. Temos nos tamanhos P (R$ 15,00), M (R$ 18,00) e G (R$ 22,00). Qual tamanho voc√™ prefere?"
                
                Cliente: "vou querer uma G. E bebida?"
                Atendente: "√ìtima escolha! üòã Anotado 1 Marmita G. Para beber, temos Coca-Cola Lata (R$ 5), Guaran√° Lata (R$ 5), √Ågua (R$ 3) e Suco de Laranja natural (R$ 8). Qual prefere?"

                =====================================================
                PRONTO PARA ATENDER O CLIENTE
                =====================================================
                """

        convo_start = [
            {'role': 'user', 'parts': [prompt_inicial]},
            {'role': 'model', 'parts': [f"Entendido. Eu sou Lyra, atendente da Marmitaria Sabor do Dia. Minha prioridade √© anotar o pedido do cliente ({final_user_name_for_prompt}), preencher o gabarito, calcular o valor total (incluindo R$ 6,00 da entrega) e usar a tag [PEDIDO_CONFIRMADO] no final. Estou pronta! Ol√°, {final_user_name_for_prompt}! üòä Nosso prato do dia hoje √© Strogonoff de Frango. Vamos fazer um pedido? üòã"]}
        ]
        
        # O restante da l√≥gica de carregar hist√≥rico e cache permanece igual
        loaded_conversation = load_conversation_from_db(contact_id)
        if loaded_conversation and 'history' in loaded_conversation:
            print(f"Iniciando chat para {sender_name} com hist√≥rico anterior.")
            old_history = [msg for msg in loaded_conversation['history'] if not msg['parts'][0].strip().startswith("A data e hora atuais s√£o:")]
            chat = modelo_ia.start_chat(history=convo_start + old_history)
        else:
            print(f"Iniciando novo chat para {sender_name}.")
            chat = modelo_ia.start_chat(history=convo_start)

        conversations_cache[contact_id] = {'ai_chat_session': chat, 'name': sender_name, 'customer_name': known_customer_name}

    chat_session = conversations_cache[contact_id]['ai_chat_session']
    customer_name_in_cache = conversations_cache[contact_id].get('customer_name')

    try:
        print(f"Enviando para a IA: '{user_message}' (De: {sender_name})")

        input_tokens = modelo_ia.count_tokens(chat_session.history + [{'role': 'user', 'parts': [user_message]}]).total_tokens
        resposta = chat_session.send_message(user_message)
        output_tokens = modelo_ia.count_tokens(resposta.text).total_tokens
        total_tokens_na_interacao = input_tokens + output_tokens

        print(f"üìä Consumo de Tokens: Entrada={input_tokens}, Sa√≠da={output_tokens}, Total={total_tokens_na_interacao}")

        ai_reply = resposta.text

        # L√≥gica de extra√ß√£o de [NOME_CLIENTE] (agora menos comum, mas mantida)
        if ai_reply.strip().startswith("[NOME_CLIENTE]"):
            print("üìù Tag [NOME_CLIENTE] detectada. Extraindo e salvando nome...")
            try:
                full_response_part = ai_reply.split("O nome do cliente √©:")[1].strip()
                extracted_name = full_response_part.split('.')[0].strip()
                start_of_message_index = full_response_part.find(extracted_name) + len(extracted_name)
                ai_reply = full_response_part[start_of_message_index:].lstrip('.!?, ').strip()

                conversation_collection.update_one(
                    {'_id': contact_id},
                    {'$set': {'customer_name': extracted_name}},
                    upsert=True
                )
                conversations_cache[contact_id]['customer_name'] = extracted_name
                customer_name_in_cache = extracted_name
                print(f"‚úÖ Nome '{extracted_name}' salvo para o cliente {contact_id}.")

            except Exception as e:
                print(f"‚ùå Erro ao extrair o nome da tag: {e}")
                ai_reply = ai_reply.replace("[NOME_CLIENTE]", "").strip()

        # --- Bloco de Processamento da Bifurca√ß√£o [PEDIDO_CONFIRMADO] ---
        # (Esta parte permanece ID√äNTICA, pois a l√≥gica de envio n√£o muda)
        if BIFURCACAO_ENABLED and ai_reply.strip().startswith("[PEDIDO_CONFIRMADO]"):
            print(f"üì¶ Tag [PEDIDO_CONFIRMADO] detectada. Processando e bifurcando pedido para {contact_id}...")
            try:
                # 1. Isolar o JSON do resto da mensagem
                json_start = ai_reply.find('{')
                json_end = ai_reply.rfind('}') + 1

                if json_start == -1 or json_end == 0:
                    raise ValueError("JSON de pedido n√£o encontrado ap√≥s a tag.")

                json_string = ai_reply[json_start:json_end]

                # 2. Isolar a mensagem de resposta para o cliente
                remaining_reply = ai_reply[json_end:].strip()
                if not remaining_reply:
                    remaining_reply = "Seu pedido foi confirmado e enviado para a cozinha! Algo mais?"  # Fallback

                # 3. Parsear o JSON
                order_data = json.loads(json_string)

                # 4. Formatar as mensagens de bifurca√ß√£o
                # Mensagem para a COZINHA (Completa)
                msg_cozinha = f"""
                --- üç≥ NOVO PEDIDO (COZINHA) üç≥ ---
                
                Cliente: {order_data.get('nome_cliente', 'N/A')}
                Telefone: {order_data.get('telefone_contato', 'N/A')}
                Endere√ßo: {order_data.get('endereco_completo', 'N/A')}
                
                --- PEDIDO ---
                {order_data.get('pedido_completo', 'N/A')}
                
                --- BEBIDAS ---
                {order_data.get('bebidas', 'N/A')}
                
                --- OBSERVA√á√ïES ---
                {order_data.get('observacoes', 'N/A')}
                
                Forma de Pagto: {order_data.get('forma_pagamento', 'N/A')}
                Valor Total: {order_data.get('valor_total', 'N/A')}
                """

                # Mensagem para o MOTOBOY (Parcial)
                msg_motoboy = f"""
                --- üõµ NOVA ENTREGA (MOTOBOY) üõµ ---
                
                Cliente: {order_data.get('nome_cliente', 'N/A')}
                Telefone: {order_data.get('telefone_contato', 'N/A')}
                Endere√ßo: {order_data.get('endereco_completo', 'N/A')}
                
                Forma de Pagto: {order_data.get('forma_pagamento', 'N/A')}
                Valor Total: {order_data.get('valor_total', 'N/A')}
                """

                # 5. Enviar as mensagens (em threads para n√£o bloquear a resposta)
                threading.Thread(target=send_whatsapp_message, args=(COZINHA_WPP_NUMBER, msg_cozinha.strip())).start()
                threading.Thread(target=send_whatsapp_message, args=(MOTOBOY_WPP_NUMBER, msg_motoboy.strip())).start()

                print(f"‚úÖ Pedido bifurcado com sucesso para {COZINHA_WPP_NUMBER} e {MOTOBOY_WPP_NUMBER}.")

                # 6. Atualiza a resposta para o cliente
                ai_reply = remaining_reply

            except Exception as e:
                print(f"‚ùå Erro ao processar bifurca√ß√£o [PEDIDO_CONFIRMADO]: {e}")
                ai_reply = ai_reply.replace("[PEDIDO_CONFIRMADO]", "").strip()
                if '{' in ai_reply and '}' in ai_reply:
                    ai_reply = "Tive um problema ao enviar seu pedido para a cozinha. Pode confirmar os dados novamente, por favor? (Erro interno: JSON_PARSE)"
                
                save_conversation_to_db(contact_id, sender_name, customer_name_in_cache, chat_session, total_tokens_na_interacao)
                return ai_reply  # Retorna a mensagem de erro
        # --- FIM DO BLOCO DE BIFURCA√á√ÉO ---

        if not ai_reply.strip().startswith("[HUMAN_INTERVENTION]"):
            save_conversation_to_db(contact_id, sender_name, customer_name_in_cache, chat_session, total_tokens_na_interacao)

        return ai_reply

    except Exception as e:
        print(f"‚ùå Erro ao comunicar com a API do Gemini: {e}")
        if contact_id in conversations_cache:
            del conversations_cache[contact_id]
        return "Tive um pequeno problema para processar sua mensagem e precisei reiniciar nossa conversa. Voc√™ poderia repetir, por favor?"

def transcrever_audio_gemini(caminho_do_audio):
    """
    Envia um arquivo de √°udio para a API do Gemini e retorna a transcri√ß√£o em texto.
    """
    global modelo_ia  # Vamos reutilizar o modelo Gemini que j√° foi iniciado

    if not modelo_ia:
        print("‚ùå Modelo de IA n√£o inicializado. Imposs√≠vel transcrever.")
        return None

    print(f"üé§ Enviando √°udio '{caminho_do_audio}' para transcri√ß√£o no Gemini...")
    try:
        audio_file = genai.upload_file(
            path=caminho_do_audio,
            mime_type="audio/ogg"
        )

        # Pedimos ao modelo para transcrever o √°udio
        response = modelo_ia.generate_content(["Por favor, transcreva o √°udio a seguir.", audio_file])

        # Opcional, mas recomendado: deletar o arquivo do servidor do Google ap√≥s o uso
        genai.delete_file(audio_file.name)

        if response.text:
            print(f"‚úÖ Transcri√ß√£o recebida: '{response.text}'")
            return response.text
        else:
            print("‚ö†Ô∏è A IA n√£o retornou texto para o √°udio. Pode ser um √°udio sem falas.")
            return None
    except Exception as e:
        print(f"‚ùå Erro ao transcrever √°udio com Gemini: {e}")
        return None


def send_whatsapp_message(number, text_message):
    """Envia uma mensagem de texto para um n√∫mero via Evolution API."""
    clean_number = number.split('@')[0]
    payload = {"number": clean_number, "textMessage": {"text": text_message}}
    headers = {"apikey": EVOLUTION_API_KEY, "Content-Type": "application/json"}

    try:
        response = requests.post(EVOLUTION_API_URL, json=payload, headers=headers)
        response.raise_for_status()
        print(f"‚úÖ Mensagem (Texto) enviada com sucesso para {clean_number}\n")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erro ao enviar mensagem para {clean_number}: {e}")


def gerar_e_enviar_relatorio_semanal():
    """Calcula um RESUMO do uso de tokens e envia por e-mail usando SendGrid."""
    print(f"üóìÔ∏è Gerando relat√≥rio semanal para o cliente: {CLIENT_NAME}...")

    SENDGRID_API_KEY = os.environ.get('SENDGRID_API_KEY')
    EMAIL_RELATORIOS = os.environ.get('EMAIL_RELATORIOS')

    if not all([SENDGRID_API_KEY, EMAIL_RELATORIOS]):
        print("‚ö†Ô∏è Vari√°veis SENDGRID_API_KEY e EMAIL_RELATORIOS n√£o configuradas. Relat√≥rio n√£o pode ser enviado.")
        return

    hoje = datetime.now()

    try:
        usuarios_do_bot = list(conversation_collection.find({}))
        numero_de_contatos = len(usuarios_do_bot)
        total_geral_tokens = 0
        media_por_contato = 0

        if numero_de_contatos > 0:
            for usuario in usuarios_do_bot:
                total_geral_tokens += usuario.get('total_tokens_consumed', 0)
            media_por_contato = total_geral_tokens / numero_de_contatos

        corpo_email_texto = f"""
        Relat√≥rio de Consumo Acumulado do Cliente: '{CLIENT_NAME}'
        Data do Relat√≥rio: {hoje.strftime('%d/%m/%Y')}

        --- RESUMO GERAL DE USO ---

        üë§ N√∫mero de Contatos √önicos: {numero_de_contatos}
        üî• Consumo Total de Tokens (Acumulado): {total_geral_tokens}
        üìä M√©dia de Tokens por Contato: {media_por_contato:.0f}

        ---------------------------
        Atenciosamente,
        Seu Sistema de Monitoramento.
        """

        message = Mail(
            from_email=EMAIL_RELATORIOS,
            to_emails=EMAIL_RELATORIOS,
            subject=f"Relat√≥rio Semanal de Tokens - {CLIENT_NAME} - {hoje.strftime('%d/%m')}",
            plain_text_content=corpo_email_texto
        )

        sendgrid_client = SendGridAPIClient(SENDGRID_API_KEY)
        response = sendgrid_client.send(message)

        if response.status_code == 202:
            print(f"‚úÖ Relat√≥rio semanal para '{CLIENT_NAME}' enviado com sucesso via SendGrid!")
        else:
            print(f"‚ùå Erro ao enviar e-mail via SendGrid. Status: {response.status_code}. Body: {response.body}")

    except Exception as e:
        print(f"‚ùå Erro ao gerar ou enviar relat√≥rio para '{CLIENT_NAME}': {e}")


app = Flask(__name__)

processed_messages = set()  # para evitar loops


@app.route('/webhook', methods=['POST'])
def receive_webhook():
    """Recebe mensagens do WhatsApp enviadas pela Evolution API."""
    data = request.json
    print(f"üì¶ DADO BRUTO RECEBIDO NO WEBHOOK: {data}")

    try:
        message_data = data.get('data', {}) or data
        key_info = message_data.get('key', {})

        # --- 1Ô∏è‚É£ Ignora mensagens enviadas por voc√™ mesmo ---
        if key_info.get('fromMe'):
            return jsonify({"status": "ignored_from_me"}), 200

        # --- 2Ô∏è‚É£ Pega o ID √∫nico da mensagem ---
        message_id = key_info.get('id')
        if not message_id:
            return jsonify({"status": "ignored_no_id"}), 200

        # --- 3Ô∏è‚É£ Se j√° processou esta mensagem, ignora ---
        if message_id in processed_messages:
            print(f"‚ö†Ô∏è Mensagem {message_id} j√° processada, ignorando.")
            return jsonify({"status": "ignored_duplicate"}), 200
        processed_messages.add(message_id)
        if len(processed_messages) > 1000:
            processed_messages.clear()

        # --- 4Ô∏è‚É£ Retorna imediatamente 200 para evitar reenvio da Evolution ---
        threading.Thread(target=process_message, args=(message_data,)).start()
        return jsonify({"status": "received"}), 200

    except Exception as e:
        print(f"‚ùå Erro inesperado no webhook: {e}")
        print("DADO QUE CAUSOU ERRO:", data)
        return jsonify({"status": "error"}), 500


def process_message(message_data):
    """Processa a mensagem, buscando dados do cliente antes de chamar a IA."""
    try:
        sender_number_full = message_data.get('key', {}).get('remoteJid')

        if not sender_number_full or sender_number_full.endswith('@g.us'):
            return

        clean_number = sender_number_full.split('@')[0]
        sender_name_from_wpp = message_data.get('pushName') or 'Cliente'
        message = message_data.get('message', {})

        user_message_content = None
        if message.get('conversation'):
            user_message_content = message['conversation']
        elif message.get('extendedTextMessage'):
            user_message_content = message['extendedTextMessage'].get('text')
        elif message.get('audioMessage') and message.get('base64'):
            print(f"üé§ Mensagem de √°udio recebida de {sender_name_from_wpp} ({clean_number}).")
            audio_base64 = message['base64']
            audio_data = base64.b64decode(audio_base64)
            temp_audio_path = f"/tmp/audio_{clean_number}.ogg"
            with open(temp_audio_path, 'wb') as f:
                f.write(audio_data)

            user_message_content = transcrever_audio_gemini(temp_audio_path)
            os.remove(temp_audio_path)

            if not user_message_content:
                send_whatsapp_message(sender_number_full, "Desculpe, n√£o consegui entender o √°udio. Pode tentar novamente? üéß")
                return

        if not user_message_content:
            print("‚û°Ô∏è Mensagem ignorada (sem conte√∫do √∫til).")
            return

        # --- L√ìGICA ADICIONADA ---
        # Busca os dados do cliente no banco ANTES de chamar a IA
        conversation_status = load_conversation_from_db(clean_number)
        known_customer_name = conversation_status.get('customer_name') if conversation_status else None

        if known_customer_name:
            print(f"üë§ Cliente j√° conhecido: {known_customer_name} ({clean_number})")
        else:
            print(f"üë§ Novo cliente ou nome desconhecido. Usando nome do WPP: {sender_name_from_wpp} ({clean_number})")

        print(f"\nüß† Processando mensagem de {sender_name_from_wpp} ({clean_number}): '{user_message_content}'")

        # --- ATUALIZADO: Passa o 'clean_number' como 'contact_phone' ---
        ai_reply = gerar_resposta_ia(clean_number, sender_name_from_wpp, user_message_content, known_customer_name, clean_number)

        if ai_reply:
            print(f"ü§ñ Resposta da IA para {sender_name_from_wpp}: {ai_reply}")
            send_whatsapp_message(sender_number_full, ai_reply)

    except Exception as e:
        print(f"‚ùå Erro fatal ao processar mensagem: {e}")


if __name__ == '__main__':
    if modelo_ia:
        print("\n=============================================")
        print(" ¬† CHATBOT WHATSAPP COM IA INICIADO")
        print(f" ¬† CLIENTE: {CLIENT_NAME}")  # Mostra para qual cliente este bot est√° rodando
        print("=============================================")
        print("Servidor aguardando mensagens no webhook...")

        scheduler = BackgroundScheduler(daemon=True, timezone='America/Sao_Paulo')
        # Agenda a fun√ß√£o para rodar todo Domingo √†s 08:00 da manh√£
        scheduler.add_job(gerar_e_enviar_relatorio_semanal, 'cron', day_of_week='sun', hour=8, minute=0)
        scheduler.start()
        print("‚è∞ Agendador de relat√≥rios iniciado. O relat√≥rio ser√° enviado todo Domingo √†s 08:00.")

        # Garante que o agendador seja desligado corretamente ao sair
        import atexit
        atexit.register(lambda: scheduler.shutdown())

        app.run(host='0.0.0.0', port=8000)
    else:
        print("\nEncerrando o programa devido a erros na inicializa√ß√£o.")
